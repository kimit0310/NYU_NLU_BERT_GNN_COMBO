{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c25949-5dd5-4f15-97b4-1a941e6c1e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1283c21-0ea9-4015-a2a5-57e574dd43c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cz/711fvhl175sdkt0679x1xxzh0000gn/T/ipykernel_22462/1905699193.py:1: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('NOTEEVENTS.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('NOTEEVENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5792928e-0d4d-4f16-82ec-61c1a9d204b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Admission Date:  [**2151-7-16**]       Discharge Date:  [**2151-8-4**]\\n\\n\\nService:\\nADDENDUM:\\n\\nRADIOLOGIC STUDIES:  Radiologic studies also included a chest\\nCT, which confirmed cavitary lesions in the left lung apex\\nconsistent with infectious process/tuberculosis.  This also\\nmoderate-sized left pleural effusion.\\n\\nHEAD CT:  Head CT showed no intracranial hemorrhage or mass\\neffect, but old infarction consistent with past medical\\nhistory.\\n\\nABDOMINAL CT:  Abdominal CT showed lesions of\\nT10 and sacrum most likely secondary to osteoporosis. These can\\nbe followed by repeat imaging as an outpatient.\\n\\n\\n\\n                            [**First Name8 (NamePattern2) **] [**First Name4 (NamePattern1) 1775**] [**Last Name (NamePattern1) **], M.D.  [**MD Number(1) 1776**]\\n\\nDictated By:[**Hospital 1807**]\\nMEDQUIST36\\n\\nD:  [**2151-8-5**]  12:11\\nT:  [**2151-8-5**]  12:21\\nJOB#:  [**Job Number 1808**]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0].at[\"TEXT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa745c5-7736-4e48-8c48-df658c038a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>179</td>\n",
       "      <td>53181</td>\n",
       "      <td>170490.0</td>\n",
       "      <td>2172-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2172-3-5**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180</td>\n",
       "      <td>20646</td>\n",
       "      <td>134727.0</td>\n",
       "      <td>2112-12-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2112-12-8**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>181</td>\n",
       "      <td>42130</td>\n",
       "      <td>114236.0</td>\n",
       "      <td>2150-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2150-2-25**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>182</td>\n",
       "      <td>56174</td>\n",
       "      <td>163469.0</td>\n",
       "      <td>2118-08-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-8-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>183</td>\n",
       "      <td>56174</td>\n",
       "      <td>189681.0</td>\n",
       "      <td>2118-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-12-7**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
       "0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
       "1     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
       "2     176       13702  167118.0  2119-05-25       NaN       NaN   \n",
       "3     177       13702  196489.0  2124-08-18       NaN       NaN   \n",
       "4     178       26880  135453.0  2162-03-25       NaN       NaN   \n",
       "5     179       53181  170490.0  2172-03-08       NaN       NaN   \n",
       "6     180       20646  134727.0  2112-12-10       NaN       NaN   \n",
       "7     181       42130  114236.0  2150-03-01       NaN       NaN   \n",
       "8     182       56174  163469.0  2118-08-12       NaN       NaN   \n",
       "9     183       56174  189681.0  2118-12-09       NaN       NaN   \n",
       "\n",
       "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0  Discharge summary      Report   NaN      NaN   \n",
       "1  Discharge summary      Report   NaN      NaN   \n",
       "2  Discharge summary      Report   NaN      NaN   \n",
       "3  Discharge summary      Report   NaN      NaN   \n",
       "4  Discharge summary      Report   NaN      NaN   \n",
       "5  Discharge summary      Report   NaN      NaN   \n",
       "6  Discharge summary      Report   NaN      NaN   \n",
       "7  Discharge summary      Report   NaN      NaN   \n",
       "8  Discharge summary      Report   NaN      NaN   \n",
       "9  Discharge summary      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  \n",
       "5  Admission Date:  [**2172-3-5**]              D...  \n",
       "6  Admission Date:  [**2112-12-8**]              ...  \n",
       "7  Admission Date:  [**2150-2-25**]              ...  \n",
       "8  Admission Date:  [**2118-8-10**]              ...  \n",
       "9  Admission Date:  [**2118-12-7**]              ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cf06364-b830-44f7-bb40-e8c6fcf43659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>religion</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>has_chartevents_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12258</td>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:09:00</td>\n",
       "      <td>2164-11-01 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SEPARATED</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2164-10-23 16:43:00</td>\n",
       "      <td>2164-10-23 23:00:00</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12263</td>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:32:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12265</td>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:36:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12269</td>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:19:00</td>\n",
       "      <td>2149-06-03 18:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2149-05-26 12:08:00</td>\n",
       "      <td>2149-05-26 19:45:00</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12270</td>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id  hadm_id            admittime            dischtime  \\\n",
       "0   12258       10006   142345  2164-10-23 21:09:00  2164-11-01 17:15:00   \n",
       "1   12263       10011   105331  2126-08-14 22:32:00  2126-08-28 18:59:00   \n",
       "2   12265       10013   165520  2125-10-04 23:36:00  2125-10-07 15:13:00   \n",
       "3   12269       10017   199207  2149-05-26 17:19:00  2149-06-03 18:42:00   \n",
       "4   12270       10019   177759  2163-05-14 20:43:00  2163-05-15 12:00:00   \n",
       "\n",
       "             deathtime admission_type         admission_location  \\\n",
       "0                  NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "1  2126-08-28 18:59:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "2  2125-10-07 15:13:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "3                  NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "4  2163-05-15 12:00:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "\n",
       "  discharge_location insurance language  religion marital_status  \\\n",
       "0   HOME HEALTH CARE  Medicare      NaN  CATHOLIC      SEPARATED   \n",
       "1       DEAD/EXPIRED   Private      NaN  CATHOLIC         SINGLE   \n",
       "2       DEAD/EXPIRED  Medicare      NaN  CATHOLIC            NaN   \n",
       "3                SNF  Medicare      NaN  CATHOLIC       DIVORCED   \n",
       "4       DEAD/EXPIRED  Medicare      NaN  CATHOLIC       DIVORCED   \n",
       "\n",
       "                ethnicity            edregtime            edouttime  \\\n",
       "0  BLACK/AFRICAN AMERICAN  2164-10-23 16:43:00  2164-10-23 23:00:00   \n",
       "1   UNKNOWN/NOT SPECIFIED                  NaN                  NaN   \n",
       "2   UNKNOWN/NOT SPECIFIED                  NaN                  NaN   \n",
       "3                   WHITE  2149-05-26 12:08:00  2149-05-26 19:45:00   \n",
       "4                   WHITE                  NaN                  NaN   \n",
       "\n",
       "             diagnosis  hospital_expire_flag  has_chartevents_data  \n",
       "0               SEPSIS                     0                     1  \n",
       "1          HEPATITIS B                     1                     1  \n",
       "2               SEPSIS                     1                     1  \n",
       "3     HUMERAL FRACTURE                     0                     1  \n",
       "4  ALCOHOLIC HEPATITIS                     1                     1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adm = pd.read_csv('/Users/iktae/Desktop/NLU/Proj/GNN_for_EHR/mimic-III/ADMISSIONS.csv')\n",
    "df_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa4fff89-5fa8-46db-a7e7-e658ae81d941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the ADMISSIONS.csv file\n",
    "admissions_df = pd.read_csv('/home/ik798/proj/preprocess/ADMISSIONS.csv', parse_dates=['ADMITTIME', 'DISCHTIME', 'DEATHTIME'])\n",
    "\n",
    "# Create a new DataFrame with the specified columns and capitalized column names\n",
    "new_admissions_df = admissions_df[['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DEATHTIME']].copy()\n",
    "\n",
    "# Calculate the 'LABEL' column\n",
    "new_admissions_df['LABEL'] = ((admissions_df['DEATHTIME'].notna()) &\n",
    "                               ((admissions_df['DEATHTIME'] - admissions_df['ADMITTIME']) <= pd.Timedelta('1 days'))).astype(int)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_admissions_df.to_csv('preprocessed_ADMISSIONS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa6f01-1003-4699-a7c1-875799dcef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "def preprocess1(x):\n",
    "    y = re.sub('\\\\[(.*?)\\\\]', '', x)  # remove de-identified brackets\n",
    "    y = re.sub('[0-9]+\\\\.', '', y)  # remove 1.2. since the segmenter segments based on this\n",
    "    y = re.sub('dr\\\\.', 'doctor', y)\n",
    "    y = re.sub('m\\\\.d\\\\.', 'md', y)\n",
    "    y = re.sub('admission date:', '', y)\n",
    "    y = re.sub('discharge date:', '', y)\n",
    "    y = re.sub('--|__|==', '', y)\n",
    "\n",
    "    # remove digits and spaces\n",
    "    y = y.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "    y = \" \".join(y.split())\n",
    "    return y\n",
    "\n",
    "def preprocessing(df_notes):\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].fillna(' ')\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].str.replace('\\n', ' ')\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].str.replace('\\r', ' ')\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].apply(str.strip)\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].str.lower()\n",
    "\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].apply(lambda x: preprocess1(x))\n",
    "\n",
    "    return df_notes\n",
    "\n",
    "# Read the preprocessed_ADMISSIONS.csv file\n",
    "preprocessed_admissions_df = pd.read_csv('/home/ik798/proj/preprocess/preprocessed_ADMISSIONS.csv')\n",
    "\n",
    "# Read the NOTEEVENTS.csv file\n",
    "noteevents_df = pd.read_csv('/home/ik798/proj/preprocess/NOTEEVENTS.csv')\n",
    "\n",
    "# Preprocess the NOTEEVENTS.csv file\n",
    "preprocessed_noteevents_df = preprocessing(noteevents_df)\n",
    "\n",
    "# Merge the preprocessed_ADMISSIONS.csv file with the preprocessed NOTEEVENTS.csv file\n",
    "merged_df = preprocessed_admissions_df.merge(preprocessed_noteevents_df[['HADM_ID', 'TEXT']], on='HADM_ID', how='left')\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_df.to_csv('merged_ADMISSIONS_NOTEEVENTS.csv', index=False)\n",
    "\n",
    "# Find rows from NOTEEVENTS.csv that do not have a match in preprocessed_ADMISSIONS.csv\n",
    "no_match_df = preprocessed_noteevents_df[~preprocessed_noteevents_df['HADM_ID'].isin(preprocessed_admissions_df['HADM_ID'])][['SUBJECT_ID', 'HADM_ID', 'TEXT']]\n",
    "\n",
    "# Save the no_match DataFrame to a CSV file\n",
    "no_match_df.to_csv('no_match_NOTEEVENTS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb98ab-12c4-45e4-8150-7ebc6bdbf59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('merged_ADMISSIONS_NOTEEVENTS.csv')\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['LABEL'])\n",
    "val_data, test_data = train_test_split(temp_data, test_size=(2/3), random_state=42, stratify=temp_data['LABEL'])\n",
    "\n",
    "# Save the train, validation, and test sets as CSV files\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "val_data.to_csv('val_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506259bf-473c-40a0-be60-ce762663d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def run_nvidia_smi():\n",
    "    while True:\n",
    "        subprocess.run(['nvidia-smi'])\n",
    "        time.sleep(120)  # Sleep for 2 minutes (120 seconds)\n",
    "\n",
    "print(\"Starting nvidia-smi monitoring...\")\n",
    "threading.Thread(target=run_nvidia_smi, daemon=True).start()\n",
    "\n",
    "print(\"Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=2)\n",
    "\n",
    "print(\"Loading and tokenizing datasets...\")\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "val_data = pd.read_csv('val_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_dataset = tokenize_data(train_data)\n",
    "val_dataset = tokenize_data(val_data)\n",
    "\n",
    "train_labels = torch.tensor(train_data['LABEL'].tolist())\n",
    "val_labels = torch.tensor(val_data['LABEL'].tolist())\n",
    "\n",
    "train_dataset['labels'] = train_labels\n",
    "val_dataset['labels'] = val_labels\n",
    "\n",
    "print(\"Creating Trainer and TrainingArguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2958a-1138-480f-8c35-14bf36398170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def run_nvidia_smi():\n",
    "    while True:\n",
    "        subprocess.run(['nvidia-smi'])\n",
    "        time.sleep(120)  # Sleep for 2 minutes (120 seconds)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data.to_dict('records')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.data[idx]\n",
    "        text = record['TEXT']\n",
    "        label = record['LABEL']\n",
    "        \n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return None\n",
    "        \n",
    "        inputs = self.tokenizer(text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        inputs[\"labels\"] = torch.tensor(label)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "print(\"Starting nvidia-smi monitoring...\")\n",
    "threading.Thread(target=run_nvidia_smi, daemon=True).start()\n",
    "\n",
    "print(\"Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=2)\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "val_data = pd.read_csv('val_data.csv')\n",
    "\n",
    "print(\"Creating CustomDataset instances...\")\n",
    "train_dataset = CustomDataset(train_data, tokenizer)\n",
    "val_dataset = CustomDataset(val_data, tokenizer)\n",
    "\n",
    "print(\"Creating Trainer and TrainingArguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    resume_from_checkpoint=\"./results/checkpoint-last\",\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "def data_collator(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    return tokenizer.pad(batch, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1c868-7ce8-4683-9a2f-2cb99e1e51ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
